#  End-to-End MLOps Pipeline for Question Answering using BERT

## ğŸ‘¥ Team Members
- Deepthi Rajagopal Gajendra  
- Tengzhe Zhang  
- Mourad Reda  

---

## 1. ğŸ“Œ Project Overview

This project implements a **complete end-to-end MLOps pipeline** for an **extractive Question Answering (QA)** task using a **BERT-based model fine-tuned on the SQuAD dataset**.

The goal of this project is not only to train a performant NLP model, but also to apply **MLOps best practices** across the entire machine learning lifecycle, including reproducibility, experiment tracking, model serving, containerisation, CI/CD, and monitoring.

---

## 2. ğŸ¯ Problem Definition & Data

### Problem Statement
Given a **context paragraph** and a **question**, the system extracts the most relevant answer span from the context.  
If the context does not contain sufficient information, the model returns **â€œno answerâ€**.

This is an **extractive Question Answering** problem.

### Dataset
- **Name:** Stanford Question Answering Dataset (SQuAD v1.1 / v2.0)
- **Source:** https://rajpurkar.github.io/SQuAD-explorer/
- **Description:**
  - Wikipedia-based context passages
  - Human-annotated questionâ€“answer pairs
  - Includes both answerable and unanswerable questions (v2.0)

---

## 3. ğŸ—ï¸ System Architecture

```text
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Original SQuAD dataset
â”‚   â””â”€â”€ processed/          # Tokenized & preprocessed data
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/               # Data loading & preprocessing
â”‚   â”œâ”€â”€ training/           # BERT fine-tuning scripts
â”‚   â”œâ”€â”€ evaluation/         # Evaluation metrics (EM, F1)
â”‚   â”œâ”€â”€ inference/          # Inference utilities
â”‚   â””â”€â”€ api/                # FastAPI application
â”‚
â”œâ”€â”€ tests/                  # Unit tests (â‰¥60% coverage)
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.train
â”‚   â””â”€â”€ Dockerfile.api
â”‚
â”œâ”€â”€ mlruns/                 # MLflow experiment tracking
â”‚
â”œâ”€â”€ .github/workflows/      # CI/CD pipelines
â”‚
â”œâ”€â”€ pyproject.toml          # Dependency management (UV)
â”œâ”€â”€ uv.lock                 # Reproducible environment
â”œâ”€â”€ .pre-commit-config.yaml
â””â”€â”€ README.md
```

 Here it is cleanly formatted in pure Markdown (.md), ready to paste directly into your README.md ğŸ‘‡

## 4. âš™ï¸ MLOps Practices

### Environment & Dependency Management
- Python environment managed using **UV**
- Dependencies defined in `pyproject.toml`
- Fully reproducible via `uv.lock`

```bash

 
 







